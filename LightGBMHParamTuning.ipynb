{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LightGBMHParamTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPknuAl4WRBWVX70cz9cpzD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlkaidCheng/example/blob/master/LightGBMHParamTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujTz3fzITC1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94d8b8c1-cdbb-4636-bcca-c04e067ba9d8"
      },
      "source": [
        "! pip install  --upgrade bayesian-optimization\n",
        "! pip install ray[tune]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.1.0\n",
            "Collecting ray[tune]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/47/7bc688d2c06c1d0fbd388b4e2725028b2792e1f652a28b848462a724c972/ray-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.17.5)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 46.1MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.27.1)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.12.0)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (20.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.6.4)\n",
            "Collecting redis>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.3MB/s \n",
            "\u001b[?25hCollecting tensorboardX; extra == \"tune\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 63.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.6.6)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (19.3.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 62.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (45.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ray[tune]) (2.4.6)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (8.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (1.8.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp->ray[tune]) (2.8)\n",
            "Building wheels for collected packages: idna-ssl\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3162 sha256=38680c0c4d0fc0c1c66f261497f97d581c591270db62962efae5e8923a2444ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built idna-ssl\n",
            "Installing collected packages: py-spy, idna-ssl, async-timeout, multidict, yarl, aiohttp, funcsigs, colorama, redis, tensorboardX, ray\n",
            "Successfully installed aiohttp-3.6.2 async-timeout-3.0.1 colorama-0.4.3 funcsigs-1.0.2 idna-ssl-1.1.0 multidict-4.7.5 py-spy-0.3.3 ray-0.8.2 redis-3.4.1 tensorboardX-2.0 yarl-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3geZUSMSTF6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "54254f28-a45d-475b-a41d-a911fb8ff212"
      },
      "source": [
        "!wget https://gitlab.cern.ch/clcheng/mlhep-googlesummerofcode/raw/master/Prerequisite/MachineLearning/QIS_EXAM_200Events.npz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 04:05:19--  https://gitlab.cern.ch/clcheng/mlhep-googlesummerofcode/raw/master/Prerequisite/MachineLearning/QIS_EXAM_200Events.npz\n",
            "Resolving gitlab.cern.ch (gitlab.cern.ch)... 188.184.30.115, 188.184.84.41, 188.184.30.144, ...\n",
            "Connecting to gitlab.cern.ch (gitlab.cern.ch)|188.184.30.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9140 (8.9K) [application/zip]\n",
            "Saving to: ‘QIS_EXAM_200Events.npz’\n",
            "\n",
            "QIS_EXAM_200Events. 100%[===================>]   8.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-08 04:05:20 (249 MB/s) - ‘QIS_EXAM_200Events.npz’ saved [9140/9140]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7a44XkRTHLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaGLH_5ITLHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_zippedarrays(arrays):\n",
        "  shape = arrays[0].shape\n",
        "  assert all(shape == arrays[0].shape for arr in arrays)\n",
        "  index = np.random.permutation(shape[0])\n",
        "  return [arr[index] for arr in arrays]\n",
        "\n",
        "def shuffle_data(input, label):\n",
        "  output = shuffle_zippedarrays([input,label])\n",
        "  return output[0], output[1]\n",
        "\n",
        "def load_data(arrays, shuffle = True):\n",
        "  data = {}\n",
        "  for key in arrays:\n",
        "    input, label = np.array([]), np.array([])\n",
        "    for klabel in arrays[key].item():\n",
        "      _input = arrays[key].item()[klabel]\n",
        "      _label = np.full((_input.shape[0],),int(klabel))\n",
        "      input = np.concatenate((input,_input),axis=0) if input.size else _input\n",
        "      label = np.concatenate((label,_label),axis=0) if label.size else _label\n",
        "    if shuffle:\n",
        "      input, label = shuffle_data(input, label)\n",
        "    data[key] = {'input': input, 'label': label}\n",
        "  return data\n",
        "def load_train_test_input_labels(arrays, shuffle = True):\n",
        "  data = load_data(arrays, shuffle)\n",
        "  return data['training_input']['input'], data['test_input']['input'], data['training_input']['label'], data['test_input']['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Qe5rB4TMKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load('QIS_EXAM_200Events.npz',allow_pickle=True)\n",
        "train_input, test_input, train_label, test_label = load_train_test_input_labels(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X8O31lLTNa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "c56c8db8-7435-472f-9f63-c09509bc7226"
      },
      "source": [
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "import ray\n",
        "from hyperopt import hp\n",
        "from ray import tune\n",
        "\n",
        "\n",
        "def LightGBMCallback(env):\n",
        "    _, metric, score, _ = env.evaluation_result_list[0]\n",
        "    tune.track.log(**{metric: score})\n",
        "\n",
        "def train_breast_cancer(params):\n",
        "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "    train_x = train_input\n",
        "    test_x = test_input\n",
        "    train_y = train_label\n",
        "    test_y = test_label\n",
        "    train_set = lgb.Dataset(train_x, label=train_y)\n",
        "    test_set = lgb.Dataset(test_x, label=test_y)\n",
        "    # Retrieve the subsample if present otherwise set to 1.0\n",
        "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
        "    \n",
        "    # Extract the boosting type\n",
        "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
        "    params['subsample'] = subsample    \n",
        "\n",
        "    # Make sure parameters that need to be integers are integers\n",
        "    for parameter_name in ['num_leaves']:\n",
        "        params[parameter_name] = int(params[parameter_name])      \n",
        "    gbm = lgb.train(\n",
        "        params,\n",
        "        train_set,\n",
        "        valid_sets=[test_set],\n",
        "        verbose_eval=False,\n",
        "        callbacks=[LightGBMCallback])\n",
        "    preds = gbm.predict(test_x)\n",
        "    pred_labels = np.rint(preds)\n",
        "    tune.track.log(\n",
        "        mean_accuracy=sklearn.metrics.accuracy_score(test_y, pred_labels),\n",
        "        done=True)\n",
        "    \n",
        "ray.shutdown()\n",
        "ray.init(webui_host='127.0.0.1')\n",
        "\n",
        "num_threads = 2\n",
        "\n",
        "space = {\n",
        "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
        "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
        "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
        "    'num_leaves': hp.quniform('num_leaves', 10, 1000, 1),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.000001), np.log(0.2)),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.5, 1.0),\n",
        "    \"objective\" : \"binary\",\n",
        "    \"verbose\" : -1,\n",
        "    \"metric\" : \"binary_logloss\"\n",
        "}\n",
        "\n",
        "algo = HyperOptSearch(\n",
        "        space,\n",
        "        max_concurrent=4,\n",
        "        metric=\"mean_accuracy\",\n",
        "        mode=\"min\")\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "! rm -r /lightgbm_result\n",
        "analysis = tune.run(\n",
        "    train_breast_cancer,\n",
        "    num_samples=100,\n",
        "    verbose =  0,\n",
        "    resources_per_trial={'gpu': 1},\n",
        "    search_alg = algo,\n",
        "    local_dir = '/lightgbm_result',\n",
        "    scheduler=AsyncHyperBandScheduler(metric=\"mean_accuracy\", mode=\"min\"))\n",
        "print(\"Best config: \", analysis.get_best_config(metric=\"mean_accuracy\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 05:11:42,019\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
            "2020-03-08 05:11:42,021\tINFO resource_spec.py:212 -- Starting Ray with 6.59 GiB memory available for workers and up to 3.3 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-03-08 05:11:42,315\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32m127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2020-03-08 05:11:44,135\tINFO function_runner.py:250 -- tune.track signature detected.\n",
            "2020-03-08 05:12:02,423\tWARNING worker.py:1058 -- The actor or task with ID ffffffffffffffff9b6acfe10100 is pending and cannot currently be scheduled. It requires {GPU: 1.000000}, {CPU: 1.000000} for execution and {GPU: 1.000000}, {CPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {CPU: 2.000000}, {memory: 6.591797 GiB}, {object_store_memory: 2.246094 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "2020-03-08 05:12:22,448\tWARNING worker.py:1058 -- The actor or task with ID ffffffffffffffff35a8fd970100 is pending and cannot currently be scheduled. It requires {CPU: 1.000000}, {GPU: 1.000000} for execution and {CPU: 1.000000}, {GPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {CPU: 2.000000}, {memory: 6.591797 GiB}, {object_store_memory: 2.246094 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "2020-03-08 05:13:32,520\tWARNING worker.py:1058 -- The actor or task with ID ffffffffffffffffbfc60e0e0100 is pending and cannot currently be scheduled. It requires {GPU: 1.000000}, {CPU: 1.000000} for execution and {GPU: 1.000000}, {CPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {CPU: 2.000000}, {memory: 6.591797 GiB}, {object_store_memory: 2.246094 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "2020-03-08 05:14:02,565\tWARNING worker.py:1058 -- The actor or task with ID ffffffffffffffff51d728160100 is pending and cannot currently be scheduled. It requires {GPU: 1.000000}, {CPU: 1.000000} for execution and {GPU: 1.000000}, {CPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {CPU: 2.000000}, {memory: 6.591797 GiB}, {object_store_memory: 2.246094 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "2020-03-08 05:14:18,355\tWARNING import_thread.py:136 -- The actor 'WrappedTrackFunc' has been exported 100 times. It's possible that this warning is accidental, but this may indicate that the same remote function is being defined repeatedly from within many tasks and exported to all of the workers. This can be a performance issue and can be resolved by defining the remote function on the driver instead. See https://github.com/ray-project/ray/issues/6240 for more discussion.\n",
            "2020-03-08 05:14:20,005\tINFO tune.py:352 -- Returning an analysis object by default. You can call `analysis.trials` to retrieve a list of trials. This message will be removed in future versions of Tune.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best config:  {'boosting_type': {'boosting_type': 'gbdt', 'subsample': 0.8069159416588685}, 'colsample_bytree': 0.8186783735937218, 'learning_rate': 0.04669483279255087, 'metric': 'binary_logloss', 'num_leaves': 714.0, 'objective': 'binary', 'reg_alpha': 0.6570397599979627, 'reg_lambda': 0.03784950639114426, 'verbose': -1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DFHP0ArUKLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}