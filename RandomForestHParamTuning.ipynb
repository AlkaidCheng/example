{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForestHParamTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPj4wsZClYwZaVyhJHlNsK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlkaidCheng/example/blob/master/RandomForestHParamTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Hv-E_T2mRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eb04166-c8f9-4218-c211-c367ba25b78e"
      },
      "source": [
        "! pip install  --upgrade bayesian-optimization\n",
        "! pip install ray[tune]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.1.0\n",
            "Collecting ray[tune]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/47/7bc688d2c06c1d0fbd388b4e2725028b2792e1f652a28b848462a724c972/ray-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 160kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n",
            "Collecting redis>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.3MB/s \n",
            "\u001b[?25hCollecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.17.5)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.27.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.12.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.6.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (20.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.0.12)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.6)\n",
            "Collecting tensorboardX; extra == \"tune\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (8.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (45.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[tune]) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ray[tune]) (2.4.6)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 32.0MB/s \n",
            "\u001b[?25hCollecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.6.6)\n",
            "Collecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from yarl<2.0,>=1.0->aiohttp->ray[tune]) (2.8)\n",
            "Building wheels for collected packages: idna-ssl\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3162 sha256=899367d39c54c2017e29937a504771ecb9c8cef9fd598310adff8588d7f006e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built idna-ssl\n",
            "Installing collected packages: redis, funcsigs, py-spy, colorama, async-timeout, multidict, yarl, idna-ssl, aiohttp, tensorboardX, ray\n",
            "Successfully installed aiohttp-3.6.2 async-timeout-3.0.1 colorama-0.4.3 funcsigs-1.0.2 idna-ssl-1.1.0 multidict-4.7.5 py-spy-0.3.3 ray-0.8.2 redis-3.4.1 tensorboardX-2.0 yarl-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-g6r6BX2nz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "31c9c2ca-201d-4554-e3c3-1f766ee237d8"
      },
      "source": [
        "!wget https://gitlab.cern.ch/clcheng/mlhep-googlesummerofcode/raw/master/Prerequisite/MachineLearning/QIS_EXAM_200Events.npz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 06:45:15--  https://gitlab.cern.ch/clcheng/mlhep-googlesummerofcode/raw/master/Prerequisite/MachineLearning/QIS_EXAM_200Events.npz\n",
            "Resolving gitlab.cern.ch (gitlab.cern.ch)... 188.185.68.13, 188.184.28.144, 188.184.30.144, ...\n",
            "Connecting to gitlab.cern.ch (gitlab.cern.ch)|188.185.68.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9140 (8.9K) [application/zip]\n",
            "Saving to: ‘QIS_EXAM_200Events.npz’\n",
            "\n",
            "\rQIS_EXAM_200Events.   0%[                    ]       0  --.-KB/s               \rQIS_EXAM_200Events. 100%[===================>]   8.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-08 06:45:15 (98.7 MB/s) - ‘QIS_EXAM_200Events.npz’ saved [9140/9140]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmN8zZV02qH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTSSn4Ce2rTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_zippedarrays(arrays):\n",
        "  shape = arrays[0].shape\n",
        "  assert all(shape == arrays[0].shape for arr in arrays)\n",
        "  index = np.random.permutation(shape[0])\n",
        "  return [arr[index] for arr in arrays]\n",
        "\n",
        "def shuffle_data(input, label):\n",
        "  output = shuffle_zippedarrays([input,label])\n",
        "  return output[0], output[1]\n",
        "\n",
        "def load_data(arrays, shuffle = True):\n",
        "  data = {}\n",
        "  for key in arrays:\n",
        "    input, label = np.array([]), np.array([])\n",
        "    for klabel in arrays[key].item():\n",
        "      _input = arrays[key].item()[klabel]\n",
        "      _label = np.full((_input.shape[0],),int(klabel))\n",
        "      input = np.concatenate((input,_input),axis=0) if input.size else _input\n",
        "      label = np.concatenate((label,_label),axis=0) if label.size else _label\n",
        "    if shuffle:\n",
        "      input, label = shuffle_data(input, label)\n",
        "    data[key] = {'input': input, 'label': label}\n",
        "  return data\n",
        "def load_train_test_input_labels(arrays, shuffle = True):\n",
        "  data = load_data(arrays, shuffle)\n",
        "  return data['training_input']['input'], data['test_input']['input'], data['training_input']['label'], data['test_input']['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtZQnA7D2sXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load('QIS_EXAM_200Events.npz',allow_pickle=True)\n",
        "train_input, test_input, train_label, test_label = load_train_test_input_labels(data)\n",
        "X = np.concatenate((train_input,test_input),axis = 0)\n",
        "Y = np.concatenate((train_label,test_label),axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ-V-hos2twI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "91d81aef-5ba5-4578-983a-84ebb4cf2400"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "import ray\n",
        "from hyperopt import hp\n",
        "from ray import tune\n",
        "\n",
        "\n",
        "def train_breast_cancer(params):\n",
        "    clf = RandomForestClassifier(**params)\n",
        "    accuracy_score = cross_val_score(clf, X, Y).mean()\n",
        "    tune.track.log(\n",
        "        mean_accuracy=accuracy_score,\n",
        "        done=True)\n",
        "    \n",
        "ray.shutdown()\n",
        "ray.init(webui_host='127.0.0.1')\n",
        "\n",
        "num_threads = 2\n",
        "\n",
        "space = {\n",
        "    # Maximum number of levels in tree\n",
        "    'max_depth': hp.choice('max_depth', range(1,100)),\n",
        "    # Number of features to consider at every split\n",
        "    'max_features': hp.choice('max_features', ['auto','sqrt']),\n",
        "    # Number of trees in random forest\n",
        "    'n_estimators': hp.choice('n_estimators', range(100,2000)),\n",
        "    # Minimum number of samples required to split a node\n",
        "    'min_samples_split' :hp.choice('min_samples_split', range(2,10)),\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    'min_samples_leaf' :hp.choice('min_samples_leaf', range(1,10)),\n",
        "    # Method of selecting samples for training each tree    \n",
        "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
        "    }\n",
        "\n",
        "algo = HyperOptSearch(\n",
        "        space,\n",
        "        max_concurrent=4,\n",
        "        metric=\"mean_accuracy\",\n",
        "        mode=\"max\")\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "! rm -r /lightgbm_result\n",
        "analysis = tune.run(\n",
        "    train_breast_cancer,\n",
        "    num_samples=100,\n",
        "    verbose =  0,\n",
        "    resources_per_trial={'gpu': 1},\n",
        "    search_alg = algo,\n",
        "    local_dir = '/randomforest_result',\n",
        "    scheduler=AsyncHyperBandScheduler(metric=\"mean_accuracy\", mode=\"max\"))\n",
        "print(\"Best config: \", analysis.get_best_config(metric=\"mean_accuracy\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 06:51:59,669\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
            "2020-03-08 06:51:59,674\tINFO resource_spec.py:212 -- Starting Ray with 6.59 GiB memory available for workers and up to 3.3 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-03-08 06:51:59,978\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32m127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/lightgbm_result': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 06:52:06,121\tINFO function_runner.py:250 -- tune.track signature detected.\n",
            "2020-03-08 06:59:10,529\tWARNING worker.py:1058 -- The actor or task with ID ffffffffffffffff8845600d0100 is pending and cannot currently be scheduled. It requires {CPU: 1.000000}, {GPU: 1.000000} for execution and {CPU: 1.000000}, {GPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {node:172.28.0.2: 1.000000}, {CPU: 2.000000}, {memory: 6.591797 GiB}, {object_store_memory: 2.246094 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
            "2020-03-08 07:12:35,512\tWARNING import_thread.py:136 -- The actor 'WrappedTrackFunc' has been exported 100 times. It's possible that this warning is accidental, but this may indicate that the same remote function is being defined repeatedly from within many tasks and exported to all of the workers. This can be a performance issue and can be resolved by defining the remote function on the driver instead. See https://github.com/ray-project/ray/issues/6240 for more discussion.\n",
            "2020-03-08 07:12:52,734\tINFO tune.py:352 -- Returning an analysis object by default. You can call `analysis.trials` to retrieve a list of trials. This message will be removed in future versions of Tune.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best config:  {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 280}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixzBpw1i4X-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}